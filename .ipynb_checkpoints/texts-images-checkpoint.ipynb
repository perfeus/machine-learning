{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXfSY8mo4QdD"
   },
   "source": [
    "\n",
    "# Extract feature from texts and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CuU5ZQtb4Qc-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Jc_YQXt4QdF"
   },
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8pH4pkQP4QdF",
    "outputId": "905d010f-e4dc-426f-a9b3-b2cb62c05128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n",
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset from sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits['images'].shape)\n",
    "print(digits['data'].shape)\n",
    "print(digits['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n9SYNAM-4QdG",
    "outputId": "9ddbf417-3e6a-41d9-9aed-e1984426221f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images contain 8x8 black'n'white pictures of hadwritten digits\n",
    "digits['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqlhH7tF4QdH"
   },
   "source": [
    "#### 1. Explore the data\n",
    "\n",
    "Let's plot several pictures, split dataset on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CbaZ9y7g4QdH",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(3, 5, figsize=(16, 5))\n",
    "axes = axes.flatten()\n",
    "plt.tight_layout()\n",
    "\n",
    "for ax, image, label in zip(axes, digits['images'], digits['target']):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title(label, size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCkuzU7f4QdI"
   },
   "source": [
    "We will assume that each pixel is a feature. Note, that images were already rechaped into vectors for us in `digits['data']` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UkivG_hl4QdJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64)\n",
      "(450, 64)\n",
      "(1347,)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits[\"data\"], digits[\"target\"])\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNezNu-g4QdK"
   },
   "source": [
    "#### 2. Train the model\n",
    "\n",
    "We can now train the model. This is a classification task with 10 classes. \n",
    "\n",
    "The model, that we will use is called `KNeighborsClassifier` (kNN). It does not have trainable parameters and works in the following manner:\n",
    "* Remember the training data\n",
    "* When new point arrives \n",
    "    * find `K` nearest points in the training dataset (e.g. by euclidean distance)\n",
    "    * return the most freaquent class among these `K`.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmoukJ2r4QdK"
   },
   "source": [
    "   Let's create and train the following pipeline:\n",
    "* Scale the input vectorized image \n",
    "* Classify by kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yEqBaOgi4QdL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()), ('clf', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# define pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"scaling\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier())])\n",
    "\n",
    "# fit\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIH9wLQ64QdL"
   },
   "source": [
    "#### 3. Evaluate on test dataset\n",
    "\n",
    "We will use accuracy - proportion of correct predictions, to measure the quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VsZohRww4QdM"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# predict on test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# compute accuracy\n",
    "score = accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ywXnQUBu4QdM",
    "outputId": "c02e83c0-4377-44c2-d13d-fcd423f523cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sszKzt_4QdM"
   },
   "source": [
    "**Optional task**\n",
    "\n",
    "Let's implement accuracy itself using numpy only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dX6f9u7G4QdN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_accuracy(true, predicted):\n",
    "    return np.where(y_pred==y_test, True, False).sum()/len(y_pred)\n",
    "    \n",
    "\n",
    "# test that your function work the same as `accuracy_score` from sklearn\n",
    "my_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDEsqWLh4QdN"
   },
   "source": [
    "## Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7Z_GqsT4QdN"
   },
   "source": [
    "### Convert documents to vectors\n",
    "\n",
    "Note that our dataset now is a set of documents (or texts): $D = (d_1, \\dots, d_N)$\n",
    "\n",
    "We will assume that there is vocabulary of size $M$, which contains all possible words, from which our documents are composed. \n",
    "\n",
    "Of course, each documents has different number of words in it. \n",
    "\n",
    "Today, we will consider 2 options how to represent texts with the vectors (embeddings):\n",
    "1. Bag of words\n",
    "2. Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4mNRe_t4QdO"
   },
   "source": [
    "Let us firstly use the simplest example to undertand how both methods work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "F981PirV4QdO"
   },
   "outputs": [],
   "source": [
    "d1 = \"This is my favourite movie\"\n",
    "d2 = \"Is this movie boring? Yes, it is!\"\n",
    "d3 = \"This is an exiting movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "K3Ba4fb74QdO",
    "outputId": "53cab14b-1097-40eb-87a9-17e0750476c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'my', 'favourite', 'movie'],\n",
       " ['is', 'this', 'movie', 'boring', 'yes', 'it', 'is'],\n",
       " ['this', 'is', 'an', 'exiting', 'movie']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "D = [re.sub('[.!?,]', '', d.lower()).split(' ') for d in [d1, d2, d3]]\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNOKR6Zi4QdP"
   },
   "source": [
    "The Vocabulary for such dataset would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Vfml28yB4QdP",
    "outputId": "f70224a2-489f-41b1-9377-007e55889106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'my', 'favourite', 'movie', 'is', 'this', 'movie', 'boring', 'yes', 'it', 'is', 'this', 'is', 'an', 'exiting', 'movie']\n",
      "['it', 'boring', 'movie', 'yes', 'exiting', 'my', 'an', 'is', 'this', 'favourite']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "all_words = sum(D, [])\n",
    "print(all_words)\n",
    "V = list(set(all_words))\n",
    "print(V, len(V), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Et98iA24QdP"
   },
   "source": [
    "#### Option 1. Bag of words\n",
    "\n",
    "We can say, that text is charaterized by the vector of length $M$, which shows how many times each word from the vector is present in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d91Ihcsc4QdQ"
   },
   "source": [
    "Let us now calculate bag of words for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6xja79zo4QdQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros((len(D), len(V)))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, v in enumerate(V):\n",
    "    for i, d in enumerate(D):\n",
    "        X[i, j] = sum([1 for w in d if w == v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 1., 0., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 2., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmepH6I64QdQ"
   },
   "source": [
    "#### Option 2. Tf-idf\n",
    "\n",
    "**Term Frequency times Inverce Document Frequency**\n",
    "\n",
    "A method to describe each document in the dataset with a vector of the same length. Takes into account, how often the word appears in the whole dataset.\n",
    "\n",
    "\n",
    "\n",
    "**Term frequency (tf)** - number of times a term occurs in a given document\n",
    "$$\n",
    "tf(t, d) = \\frac{\\# t \\text{ in } d}{len(d)}\n",
    "$$\n",
    "\n",
    "\n",
    "**Inverce document frequency (idf)** - measures informativeness of a term\n",
    "\n",
    "$$\n",
    "idf(t) = \\log \\frac{N}{(\\# d \\text{ with } t)} , N - \\text{ number of documents}\n",
    "$$\n",
    "\n",
    "If the word occures almost in all the documents (e.g. article, popular verb), then $idf$ will be very low.\n",
    "\n",
    "---\n",
    "Now we can covert each document into the vector of size $M$:\n",
    "$$\n",
    "d \\rightarrow \\left(tf(t_1, d)\\cdot idf(t_1),\\,\\, \\dots, \\,\\, tf(t_M, d) \\cdot idf(t_M)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "Let us calculate it for our simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "e0O5Sd3V4QdR",
    "outputId": "84a4a993-3e28-40f7-c733-31bd99f05e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'my', 'favourite', 'movie'], ['is', 'this', 'movie', 'boring', 'yes', 'it', 'is'], ['this', 'is', 'an', 'exiting', 'movie']] \n",
      "\n",
      "['it', 'boring', 'movie', 'yes', 'exiting', 'my', 'an', 'is', 'this', 'favourite']\n"
     ]
    }
   ],
   "source": [
    "print(D, '\\n')\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "bcq9L9we4QdR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.2       , 0.        , 0.        ,\n",
       "        0.2       , 0.        , 0.2       , 0.2       , 0.2       ],\n",
       "       [0.14285714, 0.14285714, 0.14285714, 0.14285714, 0.        ,\n",
       "        0.        , 0.        , 0.28571429, 0.14285714, 0.        ],\n",
       "       [0.        , 0.        , 0.2       , 0.        , 0.2       ,\n",
       "        0.        , 0.2       , 0.2       , 0.2       , 0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf\n",
    "tf = np.zeros((len(D), len(V)))\n",
    "\n",
    "for j, v in enumerate(V):\n",
    "    for i, d in enumerate(D):\n",
    "        tf[i, j] = sum([1 for w in d if w == v])/len(d)\n",
    "\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "dn5FjwWX4QdR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09861229, 1.09861229, 0.        , 1.09861229, 1.09861229,\n",
       "       1.09861229, 1.09861229, 0.        , 0.        , 1.09861229])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf\n",
    "idf = np.zeros(len(V))\n",
    "\n",
    "for j, v in enumerate(V):\n",
    "    idf[j] = np.log(len(D) / sum([1 for d in D if v in d]))\n",
    "\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "DlLOAI8l4QdR",
    "outputId": "ccc8db30-9daf-43db-ce42-3834b09051dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.  , 0.  , 0.22],\n",
       "       [0.16, 0.16, 0.  , 0.16, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.22, 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf*idf\n",
    "np.round(X, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx7JU9sD4QdR"
   },
   "source": [
    "**Optional task**\n",
    "\n",
    "Below we will use `BoW` and `tf-idf` features to classify texts from the dataset with news articles. \n",
    "\n",
    "### BoW and Tf-Idf in Sklearn\n",
    "\n",
    "In practice, we can use `Transformers` from sklearn to get the same vector representation of texts as we implemented above. \n",
    "\n",
    "#### 1. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 1899,
     "status": "ok",
     "timestamp": 1663443597998,
     "user": {
      "displayName": "Маргарита Бурова",
      "userId": "08611594987469395240"
     },
     "user_tz": -180
    },
    "id": "A42p6sne4QdR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073,) (1073,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: \\n: &gt;&gt; Please enlighten me.  How is omnipote...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In &lt;19APR199320262420@kelvin.jpl.nasa.gov&gt; baa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nHenry, I made the assumption that he who get...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  target\n",
       "0  : \\n: >> Please enlighten me.  How is omnipote...       0\n",
       "1  In <19APR199320262420@kelvin.jpl.nasa.gov> baa...       1\n",
       "2  \\nHenry, I made the assumption that he who get...       1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categories = ['alt.atheism', 'sci.space']\n",
    "train = pd.read_csv('https://github.com/mbburova/MDS/raw/main/train_news.csv', index_col=0)\n",
    "X_train, y_train = train.news, train.target\n",
    "print(X_train.shape, y_train.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713,) (713,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n  Damn.  And I did so have my hopes up.\\n\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had to turn to one of my problem set...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nBut if He/She did you would probably conside...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  target\n",
       "0  \\n  Damn.  And I did so have my hopes up.\\n\\n\\...       0\n",
       "1          I had to turn to one of my problem set...       1\n",
       "2  \\nBut if He/She did you would probably conside...       0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('https://github.com/mbburova/MDS/raw/main/test_news.csv', index_col=0)\n",
    "X_test, y_test = test.news, test.target\n",
    "print(X_test.shape, y_test.shape)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpaSPdBP4QdS"
   },
   "source": [
    "#### 2. Explore the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([0, 1], dtype=int64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique(), y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Z9KYgGFp4QdS",
    "outputId": "9742029c-80fd-4919-debf-e5d9ab48896b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0\n",
      ": \n",
      ": >> Please enlighten me.  How is omnipotence contradictory?\n",
      ": \n",
      ": >By definition, all that can occur in the universe is governed by the rules\n",
      ": >of nature. Thus god cannot break them. Anything that god does must be allowed\n",
      ": >in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts\n",
      ": >the rules of nature.\n",
      ": \n",
      ": Obviously, an omnipotent god can change the rules.\n",
      "\n",
      "When you say, \"By definition\", what exactly is being defined;\n",
      "certainly not omnipotence. You seem to be saying that the \"rules of\n",
      "nature\" are pre-existant somehow, that they not only define nature but\n",
      "actually cause it. If that's what you mean I'd like to hear your\n",
      "further thoughts on the question.\n",
      "-------\n",
      "\n",
      "label: 1\n",
      "In <19APR199320262420@kelvin.jpl.nasa.gov> baalke@kelvin.jpl.nasa.gov \n",
      "\n",
      "Sorry I think I missed a bit of info on this Transition Experiment. What is it?\n",
      "\n",
      "Will this mean a loss of data or will the Magellan transmit data later on ??\n",
      "\n",
      "BTW: When will NASA cut off the connection with Magellan?? Not that I am\n",
      "looking forward to that day but I am just curious. I believe it had something\n",
      "to do with the funding from the goverment (or rather _NO_ funding :-)\n",
      "\n",
      "ok that's it for now. See you guys around,\n",
      "Jurriaan.\n",
      " \n",
      "-------\n",
      "\n",
      "label: 1\n",
      "\n",
      "Henry, I made the assumption that he who gets there firstest with the mostest\n",
      "wins. \n",
      "\n",
      "Ohhh, you want to put in FINE PRINT which says \"Thou shall do wonderous R&D\n",
      "rather than use off-the-shelf hardware\"? Sorry, didn't see that in my copy.\n",
      "Most of the Pournellesque proposals run along the lines of <some dollar\n",
      "amount> reward for <some simple goal>.  \n",
      "\n",
      "You go ahead and do your development, I'll buy off the shelf at higher cost (or\n",
      "even Russian; but I also assume that there'd be some \"Buy US\" provos in there)\n",
      "and be camped out in the Moon while you are launching and assembling little\n",
      "itty-bitty payloads in LEO with your laser or gas gun.  And working out the\n",
      "bugs of assembly & integration in LEO. \n",
      "\n",
      "Oh, hey, could I get a couple of CanadARMs tuned for the lunar environment?  I\n",
      "wanna do some teleoperated prospecting while I'm up there...\n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('label:',y_train[i])\n",
    "    print(X_train[i])\n",
    "    print('-------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-c1nD2jP4QdS"
   },
   "source": [
    "#### 3.1 BoW \n",
    "\n",
    "Our pipeline:\n",
    "* BoW vectorizer\n",
    "* kNN classifier\n",
    "\n",
    "We will use accuracy to evaluate model on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "43ND2XcG4QdS"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "ZTi9h2AD4QdS"
   },
   "outputs": [],
   "source": [
    "# Define traning pipeline\n",
    "bow = CountVectorizer(min_df=0.1, stop_words='english')\n",
    "# your code here\n",
    "pipe = Pipeline([(\"countVec\", bow), (\"clf\", KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countVec', CountVectorizer(min_df=0.1, stop_words='english')),\n",
       "                ('clf', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on train data\n",
    "X_train = X_train.values.astype(\"U\")\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data (compute accuracy)\n",
    "# your code here\n",
    "X_test = X_test.values.astype(\"U\")\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6227208976157083"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4LZD-KT4QdT"
   },
   "source": [
    "#### 3.2 Tf-Idf\n",
    "\n",
    "Let's repeat the same procedure, but for tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define traning pipeline\n",
    "tf_idf = TfidfVectorizer(sublinear_tf=True, min_df=0.1, stop_words='english')\n",
    "\n",
    "pipe = Pipeline([(\"tfidfVec\", tf_idf), (\"clf\", KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfVec',\n",
       "                 TfidfVectorizer(min_df=0.1, stop_words='english',\n",
       "                                 sublinear_tf=True)),\n",
       "                ('clf', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on train data\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data (compute accuracy)\n",
    "\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "8FurFH7_4QdT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6661991584852734"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
